[{"content":"创建新网站 hugo new site 网站名字 hugo开启服务 hugo server --buildDrafts hugo serve hugo server -D 三种方式都可以\n新建文件 hugo new 文件目录/文件名.zh.md hugo new 文件目录/文件目录/文件名.zh.md 新建章节 hugo new --kind chapter 文件目录/_index.zh.md 文件_index.zh.md里面改为 chapter = true\n添加主题 // 进入主题目录 cd themes/ // 克隆learn主题 git clone https://github.com/matcornic/hugo-theme-learn.git 把exampleSite下面的config.toml文件复制到站点下,修改config.toml文件里面的themes = \u0026ldquo;learn\u0026rdquo;\n打包部署 hugo # hugo -F --cleanDestinationDir # 加了上述参数表示表示每次生成的public都是全新的，会覆盖原来的。 生成文件夹public，其中包含网站的所有静态内容，可以部署在任何 Web 服务器上。\n","permalink":"/posts/tech/hugo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"创建新网站 hugo new site 网站名字 hugo开启服务 hugo server --buildDrafts hugo serve hugo server -D 三种方式都可以 新建文件 hugo new 文件目录/文件名.zh.md hugo new 文件目录/文件目录/文件名.zh.md 新建章节 hugo new --kind chapter 文件目录/_index.zh.md 文件_index.zh.md里面改为 chapter = true 添加主题 // 进入主题目录 cd themes/ // 克隆le","title":"Hugo常用命令"},{"content":"注：只提供部署三台MySQL服务器的流程，基于MySQL的MGR特性。没有主从关系，每个节点都是一样的。 部署多台的服务方式一样，只需简单的修改几个地方的配置。\n案例环境说明 节点 ip 端口 作用 节点1 (chenxiaoju3) 192.168.1.89 3306 MySQL部署 节点2 (chenxiaoju4） 192.168.1.91 3306，6033 MySQL部署+ProxySQL 节点3(chenxiaoju17) 192.168.1.17 3306 MySQL部署 安装各节点的MySQL服务 一、建设目录和磁盘挂载 在宿主机上建立如下目录\n/dascom/mysql/config /dascom/mysql/db 命令：\nmkdir -p /dascom/mysql/config /dascom/mysql/db 目录说明： |-/dascom v10所有服务目录 |-mysql 表示mysql数据库服务，对应的服务的启动脚本等都会放到这里 |-config mysql数据库的配置路径 |-db 数据库数据存放路径 ::: 🤔 重要提示\ndb目录是数据存放的目录，一开始磁盘挂载要分配好合理的空间。否则后期空间满了不好处理。 :::\n二、上传配置文件和启动脚本 注：三台MySQL节点服务器都一样的步骤。\n2.1 上传配置文件 创建配置文件放到/dascom/mysql/config目录下，名称如下\nconfig.cnf 内容配置解释：\n[mysqld] #忽略大小写 lower_case_table_names=1 # 最大连接数 max_connections=1024 # 服务端使用的字符集 character-set-server=utf8mb4 # 密码插件 authentication_policy=mysql_native_password #GTID: #当前节点的id。每个节点都不能一样 server_id=1 gtid_mode=on enforce_gtid_consistency=on #binlog binlog_checksum=NONE log_bin=mysql-bin log_replica_updates=1 binlog_format=row sync_source_info=1 sync_binlog=1 #relay log skip_replica_start=1 #添加插件 plugin_load_add=\u0026#39;group_replication.so\u0026#39; #MGR主要配置 #组的名字可以随便起,但不能用主机的GTID! 所有节点的这个组名必须保持一致！ loose-group_replication_group_name=\u0026#34;d6eee5a1-4124-11ec-bbec-0242ac110003\u0026#34; #为了避免每次启动自动引导具有相同名称的第二个组,所以设置为OFF。 loose-group_replication_start_on_boot=off #当前机器的地址,后面的端口根据官网以上24901,24901...随便即可。 loose-group_replication_local_address=\u0026#34;192.168.1.89:24901\u0026#34; #组的全部地址 loose-group_replication_group_seeds=\u0026#34;192.168.1.89:24901,192.168.1.91:24901\u0026#34; loose-group_replication_bootstrap_group=off loose-group_replication_single_primary_mode=off #开启多主模式的参数 loose-group_replication_enforce_update_everywhere_checks=on #读写一致性的策略配置，数据延迟的关键配置 group_replication_consistency=BEFORE 2.2 上传启动脚本 创建启动脚本到服务器/dascom/mysql路径下。文件名字：\ndascom-mysql-deploy 修改文件可执行\nchmod +x dascom-mysql-deploy 启动脚本命令解释：\n#!/bin/bash #author :chenxj docker run \\ --name dascom-mysql \\ #容器名字 --privileged=true \\ #提升容器权限 --restart=always \\ #随docker启动 --net=host \\ #docker的网络桥接模式，=host表示和宿主机在同一个网络中，使用宿主机的IP和端口 -v /dascom/mysql/db:/var/lib/mysql \\ #挂载数据存储目录 -v /dascom/mysql/config:/etc/mysql/conf.d \\ #配置文件的映射 -v /etc/localtime:/etc/localtime \\ #容器时区问题 -e MYSQL_ROOT_PASSWORD=dascom \\ #数据库root用户的密码配置 -d mysql:8.0.27 --lower_case_table_names=1 2.3 修改各节点的hosts文件（重要） 修改各节点的hosts文件，配置组内节点的主机名和IP\nvim /etc/hosts 获取主机名的命令\nhostname 添加以下内容\n... 192.168.1.89 chenxiaoju3 192.168.1.91 chenxiaoju4 192.178.1.17 chenxiaoju 重启网络\nservice network restart 三、 修改配置，启动并执行组同步操作 3.1 节点1 192.168.1.89（引导节点） 1）修改配置文件 修改配置文件的中以下几项为以下值\n#当前节点的id。每个节点都不能一样 server_id=1 #当前机器的地址,后面的端口根据官网以上24901,24901...随便即可。 loose-group_replication_local_address=\u0026#34;192.168.1.89:24901\u0026#34; #组的全部地址 loose-group_replication_group_seeds =\u0026#34;192.168.1.89:24901,192.168.1.91:24902,192.168.1.17:24903\u0026#34; 2）启动服务 ./dascom-mysql-deploy 3) 使用MySQL客户端工具连接，配置MGR 如果有防火墙，记得开发3306 和 24901端口\n192.168.1.89:3306 工具连接上以后，直接运行以下命令，一个一个(“;”号结尾)的运行。(#开头的省略)\n#创建复制账户 SET SQL_LOG_BIN=0; CREATE USER repl@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;repl\u0026#39;; GRANT REPLICATION SLAVE ON *.* TO repl@\u0026#39;%\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES; SET SQL_LOG_BIN=1; #配置复制信息命令 CHANGE REPLICATION SOURCE TO SOURCE_USER=\u0026#39;repl\u0026#39;, SOURCE_PASSWORD=\u0026#39;repl\u0026#39; FOR CHANNEL \u0026#39;group_replication_recovery\u0026#39;; #引导节点需要设置ON，否则一直识别不到其他节点（因为其他节点还没有启动） SET GLOBAL group_replication_bootstrap_group=ON; #开启组复制 START GROUP_REPLICATION; #恢复参数 SET GLOBAL group_replication_bootstrap_group=OFF; #查看组状态 SELECT * FROM performance_schema.replication_group_members; 最终出现以下界面，状态是ONLINE表示成功！\n3.2 节点2 192.168.1.91（其他节点） 1）修改配置文件 修改配置文件的中以下几项为以下值\n#当前节点的id。每个节点都不能一样 server_id=2 #当前机器的地址,后面的端口根据官网以上24901,24901...随便即可。 loose-group_replication_local_address=\u0026#34;192.168.1.91:24902\u0026#34; #组的全部地址 loose-group_replication_group_seeds =\u0026#34;192.168.1.89:24901,192.168.1.91:24902,192.168.1.17:24903\u0026#34; 2）启动服务 ./dascom-mysql-deploy 3) 使用MySQL客户端工具连接，配置MGR 如果有防火墙，记得开发3306和24902端口\n192.168.1.91:3306 工具连接上以后，直接运行以下命令，一个一个(“;”号结尾)的运行。(#开头的省略)\n#创建复制账户 SET SQL_LOG_BIN=0; CREATE USER repl@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;repl\u0026#39;; GRANT REPLICATION SLAVE ON *.* TO repl@\u0026#39;%\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES; SET SQL_LOG_BIN=1; #配置复制信息命令 CHANGE REPLICATION SOURCE TO SOURCE_USER=\u0026#39;repl\u0026#39;, SOURCE_PASSWORD=\u0026#39;repl\u0026#39; FOR CHANNEL \u0026#39;group_replication_recovery\u0026#39;; #重置同步日志文件 RESET MASTER; #开启组复制 START GROUP_REPLICATION; #查看组状态 SELECT * FROM performance_schema.replication_group_members; 最终出现以下界面，状态是ONLINE表示成功！\n3.3 节点2 192.168.1.17（其他节点） 1）修改配置文件 修改配置文件的中以下几项为以下值\n#当前节点的id。每个节点都不能一样 server_id=2 #当前机器的地址,后面的端口根据官网以上24901,24901...随便即可。 loose-group_replication_local_address=\u0026#34;192.168.1.19:24903\u0026#34; #组的全部地址 loose-group_replication_group_seeds =\u0026#34;192.168.1.89:24901,192.168.1.91:24902,192.168.1.17:24903\u0026#34; 2）启动服务 ./dascom-mysql-deploy 3) 使用MySQL客户端工具连接，配置MGR 如果有防火墙，记得开发3306和24902端口\n192.168.1.17:3306 工具连接上以后，直接运行以下命令，一个一个(“;”号结尾)的运行。(#开头的省略)\n#创建复制账户 SET SQL_LOG_BIN=0; CREATE USER repl@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;repl\u0026#39;; GRANT REPLICATION SLAVE ON *.* TO repl@\u0026#39;%\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES; SET SQL_LOG_BIN=1; #配置复制信息命令 CHANGE REPLICATION SOURCE TO SOURCE_USER=\u0026#39;repl\u0026#39;, SOURCE_PASSWORD=\u0026#39;repl\u0026#39; FOR CHANNEL \u0026#39;group_replication_recovery\u0026#39;; #重置同步日志文件 RESET MASTER; #开启组复制 START GROUP_REPLICATION; #查看组状态 SELECT * FROM performance_schema.replication_group_members; 最终出现以下界面，状态是ONLINE表示成功！\n现在，随便在其中一台上添加数据，另外两台都会同步数据！！！\n安装ProxySQL服务 ::: 🤔 版本\nProxySQL: 2.3.2 :::\nProxySQL官方文档\n一、建设目录和磁盘挂载 在宿主机上建立如下目录\n/dascom/proxysql/config /dascom/proxysql/db 命令：\nmkdir -p /dascom/proxysql/config /dascom/proxysql/db 目录说明： |-/dascom v10所有服务目录 |-proxysql 表示ProxySQL数据库服务，对应的服务的启动脚本等都会放到这里 |-config ProxySQL数据库的配置路径 |-db 数据库数据存放路径 ::: 🤔 重要提示\ndb目录是数据存放的目录，一开始磁盘挂载要分配好合理的空间。否则后期空间满了不好处理。 :::\n二、上传配置文件并修改 创建配置文件到/dascom/proxysql/config目录下，文件名称\nproxysql.cnf 内容配置解释：\n#数据存放目录，默认不用修改，会挂载到主机的/dascom/proxysql/db目录 datadir=\u0026#34;/var/lib/proxysql\u0026#34; #全局主配置信息 admin_variables= { admin_credentials=\u0026#34;admin:admin;radmin:radmin\u0026#34; #控制台用户和密码 admin只能本机访问，radmin可以远程访问 mysql_ifaces=\u0026#34;0.0.0.0:6032\u0026#34; #控制台端口 web_enabled=\u0026#34;true\u0026#34; #启用web监控界面 } mysql_variables= { threads=4 max_connections=3000 default_query_delay=0 default_query_timeout=36000000 have_compress=true poll_timeout=2000 interfaces=\u0026#34;0.0.0.0:6033\u0026#34; #项目连接的端口 6033 和 mysql 3306。 发现规律了吗？ default_schema=\u0026#34;information_schema\u0026#34; stacksize=1048576 server_version=\u0026#34;8.0.27\u0026#34; connect_timeout_server=3000 monitor_username=\u0026#34;root\u0026#34; monitor_password=\u0026#34;dascom\u0026#34; monitor_history=600000 monitor_connect_interval=60000 monitor_ping_interval=10000 monitor_read_only_interval=1500 monitor_read_only_timeout=500 ping_interval_server_msec=120000 ping_timeout_server=500 commands_stats=true sessions_sort=true connect_retries_on_failure=10 } #mysql 服务的配置，几台服务配置几条数据 #hostgroup必须一致 weight权重 max_connections最大连接数，需要小于mysql配置的最大连接数，否则使用过程中会报错，默认值1000 mysql_servers = ( { address=\u0026#34;192.168.1.89\u0026#34; , port=3306 , hostgroup=1, weight=10, max_connections=1000 }, { address=\u0026#34;192.168.1.91\u0026#34; , port=3306 , hostgroup=1, weight=10, max_connections=1000 }, { address=\u0026#34;192.168.1.17\u0026#34; , port=3306 , hostgroup=1, weight=10, max_connections=1000 } ) # mysql服务连接的用户配置 # 用户的配置一定是后端的MySQL的连接用户 #default_hostgroup 管理的组就是上面servers的hostgroup，否则使用该用户连不上servers的服务。 #max_connections 最大连接数，一般就是上面servers的最大连接数总和 mysql_users: ( { username = \u0026#34;root\u0026#34; password = \u0026#34;dascom\u0026#34; default_hostgroup = 1 active = 1 max_connections=3000 } ) 🤔 需要修改的配置\n1.mysql_servers块， 配置后端MySQL的所有服务，最大连接数等信息 2.mysql_users块 三、上传启动脚本，并启动 创建启动脚本到/dascom/proxysql目录下，名称如下：\ndascom-proxysql-deploy 修改可执行：\nchmod +x dascom-proxysql-deploy 脚本解释：\n#!/bin/bash #author: chenxj docker run \\ --name dascom-proxysql \\ #容器名 --privileged=true \\ --restart=always \\ #随docker启动 -p 6032:6032 \\ #映射控制台端口 -p 6033:6033 \\ #映射平台连接端口 -p 6080:6080 \\ #映射web监控页面端口 -v /dascom/proxysql/config/proxysql.cnf:/etc/proxysql.cnf \\ #配置文件挂载 -v /dascom/proxysql/db:/var/lib/proxysql \\ #数据存放目录挂载 -d proxysql/proxysql:2.3.2 \\ 启动服务：\n./dascom-proxysql-deploy 查看是否启动成功\n执行命令：\ndocker ps --filter \u0026#34;name=dascom-proxysql\u0026#34; 出现STATUS 是UP状态表示启动成功\n::: 🤔 端口说明\nip: 6032 控制台的端口，比如使用SQLyog连接就是连这个端口，或者使用MariaDB本机通过admin用户连接的端口 ip:6033 项目连接的端口， 和MySQL默认的3306刚好相反 ip:6080 ProxySQL 的web监控端口，浏览器输入 https://ip:6080 stats/stats可以看到一些监控信息，如连接数...。 注意是https！！！ :::\n四、测试连接 如果有防火墙，需要开放上面的三个端口\n#开放端口 firewall-cmd --zone=public --add-port=6033/tcp --permanent firewall-cmd --zone=public --add-port=6032/tcp --permanent firewall-cmd --zone=public --add-port=6080/tcp --permanent #重启防火墙 systemctl restart firewalld 使用客户端连接工具 SQLyog (其他也行)连接6032端口。\n账号和密码是上面配置的\nusername: radmin password: radmin 执行sql查看配置信息\n#servers的配置 SELECT * FROM mysql_servers; #配置的后端用户信息 SELECT * FROM mysql_users; OK！ 一切完成！！！ 其他的数据的操作和正常的数据库操作一样。\n","permalink":"/posts/blog/mysql_cluster_deploy/","summary":"注：只提供部署三台MySQL服务器的流程，基于MySQL的MGR特性。没有主从关系，每个节点都是一样的。 部署多台的服务方式一样，只需简单的修改几个地方的配置。 案例环境说明 节点 ip 端口 作用 节点1 (chenxiaoju3) 192.168.1.89 3306 MySQL部署 节点2 (chenxiaoju4） 192.168.1.91 3306，6033 MySQL部署+P","title":"MySQL集群部署"},{"content":"一、前言 ​\t因为现在的架构采用的是单一数据源的形式，在并发请求大的时候，应用是可以集群的，所以应用层不是我们的瓶颈，而数据库变成了我们的瓶颈，所以也提供数据库集群的方案。\n​\t目前采用的数据库是MySQL，针对MySQL的集群，MySQL自己就提供了支持，即主从复制，从主从复制中又引生出了多种主从方案，如单主多从，多主多从\u0026hellip;。\n​\t在MySQL的主从复制中，总有一个问题是不可避免的，那就是从库的数据延迟问题，只支持数据的最终一致性，根据实际的情况，可能会出现几秒甚至到几小时的延迟。那么有没有办法解决这个问题呢？有。在MySQL5.7.17版本推出了一个新功能，那就是MySQL Group Replication （MGR）组复制。基于组的概念，把一群数据库放到一组中，写的数据要等所有的数据库都提交了再返回，但是在MGR中，还是存在数据一致性的问题。是在MySQL8.0.14版本增加了一个新特性：MGR读写一致性；添加参数group_replication_consistenc来控制数据一致性的问题。通过配置该参数的不同值，可以彻底的达到读写一致性。\n​\t如果使用MGR，在写数据的时候，性能会略有下降，V10中，考虑我们在写数据时是可以容忍一部分（如果是三台服务器集群，延长大约几十毫秒）等待时长的，但是数据的一致性问题要得以保证。所以我们考虑采用MGR强读写一致性。\n二、数据库代理 ​\t要使用多台的MySQL数据库集群，那么就需要考虑代理的问题，要统一访问点。在数据库代理这一块，也有很多的解决方案，如主流的：\nMycat : 开源社区维护，用的人挺多的，社区也比较活跃，但是目前官方提供的只支持到5.7的版本，经过测试，支持MySQL8.0以上需要修改一下源码来兼容。\nMySQL-proxy : MySQL同源产品，但是后面基本不维护了，不少其他代理中间件是在它的基础上加强的。\nAtlas ： 360开源的，算比较活跃，基于MySQL-proxy修改的。\n\u0026hellip;\n​ 然而在对比多个中间件的后，我们采用了另一个中间件，ProxySQL。一个基于GPL协议开源的MySQL代理中间件，提供动态配置，监控\u0026hellip;等等强大的功能，并且维护也稳定，各文档也丰富。\n三、架构 综上所述，我们的数据集群架构图如下：\n🤔 说明\n数据库中间的代理层是可以随时去掉的，去掉后数据库就只能使用单台，不能使用多台数据库做负载均衡。 四、部署 MySQL集群部署\r日期: 2023-03-27\r\u0026nbsp;\r标签:\r#MySQL\u0026nbsp;\r注：只提供部署三台MySQL服务器的流程，基于MySQL的MGR特性。没有主从关系，每个节点都是一样的。 部署多台的服务方式一样，只需简单的修改几个地方的配置。 案例环境说明 节点 ip 端口 作用 节点1 (chenxiaoju3) 192.168.1.89 3306 MySQL部署 节点2 (chenxiaoju4） 192.168.1.91 3306，6033 MySQL部署\u0026#43;P ......\r","permalink":"/posts/blog/mysql_cluster/","summary":"一、前言 ​ 因为现在的架构采用的是单一数据源的形式，在并发请求大的时候，应用是可以集群的，所以应用层不是我们的瓶颈，而数据库变成了我们的瓶颈，所以也提供数据库集群的方案。 ​ 目前采用的数据库是MySQL，针对MySQL的集群，MySQL自己就提供了支持，即主从复制，从主从复制中又引生","title":"MySQL集群方案"},{"content":"镜像管理 images docker images ： 列出本地镜像。\ndocker images -a #列出本地所有的镜像 docker images -p #只显示镜像ID 语法：\ndocker images [OPTIONS] [REPOSITORY[：TAG]] OPTIONS说明：\n-a ：列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； \u0026ndash;digests ：显示镜像的摘要信息； -f ：显示满足条件的镜像； \u0026ndash;format ：指定返回值的模板文件； \u0026ndash;no-trunc ：显示完整的镜像信息； -q ：只显示镜像ID。 rmi docker rmi ： 删除本地一个或多个镜像。\n语法：\ndocker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明：\n-f ：强制删除； \u0026ndash;no-prune ：不移除该镜像的过程镜像，默认移除； save docker save ： 将指定镜像保存成 tar 归档文件。\n语法：\ndocker save [OPTIONS] IMAGE [IMAGE...] OPTIONS 说明：\n-o ：输出到的文件。 load docker load ： 导入使用 docker save 命令导出的镜像。\n语法：\ndocker load [OPTIONS] OPTIONS 说明：\n\u0026ndash;input , -i ： 指定导入的文件，代替 STDIN。 \u0026ndash;quiet , -q ： 精简输出信息。 容器操作 ps docker ps ： 列出容器\n语法：\ndocker ps [OPTIONS] OPTIONS说明：\n-a ：显示所有的容器，包括未运行的。 -f ：根据条件过滤显示的内容。 \u0026ndash;format ：指定返回值的模板文件。 -l ：显示最近创建的容器。 -n ：列出最近创建的n个容器。 \u0026ndash;no-trunc ：不截断输出。 -q ：静默模式，只显示容器编号。 -s ：显示总的文件大小。 inspect docker inspect ： 获取容器/镜像的元数据。\n语法：\ndocker inspect [OPTIONS] NAME|ID [NAME|ID...] OPTIONS说明：\n-f ：指定返回值的模板文件。 -s ：显示总的文件大小。 \u0026ndash;type ：为指定类型返回JSON。 logs docker logs ： 获取容器的日志\n#查看容器mynginx从2016年7月1日后的最新10条日志。 docker logs --since=\u0026#34;2016-07-01\u0026#34; --tail=10 mynginx 语法：\ndocker logs [OPTIONS] CONTAINER OPTIONS说明：\n-f ：跟踪日志输出 \u0026ndash;since ：显示某个开始时间的所有日志 -t ： 显示时间戳 \u0026ndash;tail ：仅列出最新N条容器日志 top **docker top ：**查看容器中运行的进程信息，支持 ps 命令参数。\n语法：\ndocker top [OPTIONS] CONTAINER [ps OPTIONS] 容器运行时不一定有/bin/bash终端来交互执行top命令，而且容器还不一定有top命令，可以使用docker top来实现查看container中正在运行的进程。\n容器生命周期管理 run **docker run ：**创建一个新的容器并运行一个命令\n语法：\ndocker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS说明：\n-a stdin： 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d： 后台运行容器，并返回容器ID； -i： 以交互模式运行容器，通常与 -t 同时使用； -P： 随机端口映射，容器内部端口随机映射到主机的端口 -p： 指定端口映射，格式为：主机(宿主)端口：容器端口 -t： 为容器重新分配一个伪输入终端，通常与 -i 同时使用； \u0026ndash;name=\u0026ldquo;nginx-lb\u0026rdquo;： 为容器指定一个名称； \u0026ndash;dns 8.8.8.8：指定容器使用的DNS服务器，默认和宿主一致； \u0026ndash;dns-search example.com：指定容器DNS搜索域名，默认和宿主一致； -h \u0026ldquo;mars\u0026rdquo;：指定容器的hostname； -e username=\u0026ldquo;ritchie\u0026rdquo;：设置环境变量； \u0026ndash;env-file=[]：从指定文件读入环境变量； \u0026ndash;cpuset=\u0026ldquo;0-2\u0026rdquo; or \u0026ndash;cpuset=\u0026ldquo;0,1,2\u0026rdquo;： 绑定容器到指定CPU运行； -m ：设置容器使用内存最大值； \u0026ndash;net=\u0026ldquo;bridge\u0026rdquo;： 指定容器的网络连接类型，支持 bridge/host/none/container： 四种类型； \u0026ndash;link=[]： 添加链接到另一个容器； \u0026ndash;expose=[]： 开放一个端口或一组端口； \u0026ndash;volume , -v： 绑定一个卷 \u0026ndash;restart=always：容器随docker启动 \u0026ndash;privileged=true： 容器内的root拥有真正的root权限 start/stop/restart ocker start ：启动一个或多个已经被停止的容器\ndocker stop ：停止一个运行中的容器\ndocker restart ：重启容器\n语法：\ndocker start [OPTIONS] CONTAINER [CONTAINER...] docker stop [OPTIONS] CONTAINER [CONTAINER...] docker restart [OPTIONS] CONTAINER [CONTAINER...] rm **docker rm ：**删除一个或多个容器。\n语法：\ndocker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明：\n-f ：通过 SIGKILL 信号强制删除一个运行中的容器。 -l ：移除容器间的网络连接，而非容器本身。 -v ：删除与容器关联的卷。 exec **docker exec ：**在运行的容器中执行命令\ndocker exec -it nginx bash #进入容器 语法：\ndocker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明：\n-d ：分离模式： 在后台运行 -i ：即使没有附加也保持STDIN 打开 -t ：分配一个伪终端 仓库管理 登录仓库\ndocker login --username=你的仓库设置的用户名 仓库地址 标记镜像版本\ndocker tag [imageId] 仓库地址/镜像名：版本号 推送镜像\ndocker push 仓库地址/镜像名：版本号 其他命令 cp **docker cp ：**用于容器与主机之间的数据拷贝。\n语法：\ndocker cp [OPTIONS] CONTAINER：SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER：DEST_PATH OPTIONS说明：\n-L ：保持源目标中的链接 stats docker stats： 用来返回运行中的容器的实时数据流。\n语法：\ndocker stats [OPTIONS] [CONTAINER...] OPTIONS说明：\n-a, \u0026ndash;all ： 显示所有容器(默认显示正在运行) \u0026ndash;format string： 使用Go模板打印漂亮的图像 \u0026ndash;no-stream： 禁用流统计，只提取第一个结果 查看某个容器占用内存 docker ps #查看容器ID，如为42efa33d1fa3 ps -ef | grep 42efa33d1fa3 #查看此容器进程号，假设为158666 pmap -d 158666或top -p 158666 #即可查看此容器占用内存情况 组合命令 #停止所有的container，这样才能够删除其中的images： docker stop $(docker ps -a -q) #如果想要删除所有container的话再加一个指令： docker rm $(docker ps -a -q) #要删除全部image的话 docker rmi $(docker images -q) 🤔 说明\n本文只列出一些平时比较常用的命令，其他命令可自行查询\n","permalink":"/posts/tech/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"镜像管理 images docker images ： 列出本地镜像。 docker images -a #列出本地所有的镜像 docker images -p #只显示镜像ID 语法： docker images [OPTIONS] [REPOSITORY[：TAG]] OPTIONS说明： -a ：列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； \u0026ndash;digests ：显示镜像的摘要信息； -f ：显示满足条件的镜像； \u0026ndash;format ：指定返回值的","title":"Docker常用命令"},{"content":"本安装教程是基于Centos7版本的。并且系统已经安装了yum工具。\n一.安装 docker有两个版本（EE）企业版， （CE）社区版。 社区版是开源免费的。所以我们安装的是社区版的。\n步骤如下：\n1.安装 yum 配置管理工具 yum install -y yum-utils device-mapper-persistent-data lvm2 2.设置 Docker 安装源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 注： yum-config-manager命令找不到的解决方法，再执行一遍以下命令\nyum install -y yum-utils 3.安装docker-ce， 安装正在使用的版本 yum -y install docker-ce-19.03.1-3.el7 其他说明：\n# 安装最新版的docker-ce yum install -y docker-ce # 查看仓库中所有的docker版本 yum list docker-ce --showduplicates | sort -r 4.配置docker 新建或修改: /etc/docker/daemon.json\n#如果没有目录，执行以下命令创建目录 mkdir -p /etc/docker #打开文件 vim /etc/docker/daemon.json 添加以下内容：\n{ \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://zbcd7wks.mirror.aliyuncs.com\u0026#34;], \u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;500m\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34;} } 配置说明：\n#配置加速器 { #docker中国官方镜像加速 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;] #阿里云镜加速器。因为我们的发布镜像存在阿里云，所以我们之间配置阿里云的镜像加速 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://zbcd7wks.mirror.aliyuncs.com\u0026#34;] } #配置docker日志 { \u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;500m\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34;} } #配置日志： #max-size=500m，意味着一个容器日志大小上限是500M， #max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。 如果是公司内部使用内部镜像，需要配置私服地址\n#配置私服的地址 { \u0026#34;insecure-registries\u0026#34;: [\u0026#34;192.168.1.33:1027\u0026#34;] } 5.启动docker 一定要确保第5步的格式没有问题，否则 docker 无法启动，修改完成后执行以下命令：\nsystemctl daemon-reload #重新加载配置文件 启动命令\nsystemctl enable docker #设置开机启动 systemctl start docker #启动 systemctl disable docker #关闭开机启动 注：需要设置开机启动docker。否则服务器重启不会自动启动项目\n6.检查是否成功 执行命令：\ndocker version 出现以下内容，表示启动成功。\n[root@chenxiaoju ~]# docker version Client: Docker Engine - Community Version: 20.10.8 API version: 1.40 Go version: go1.16.6 Git commit: 3967b7d Built: Fri Jul 30 19:55:49 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 19.03.1 API version: 1.40 (minimum version 1.12) Go version: go1.12.5 Git commit: 74b1e89 Built: Thu Jul 25 21:19:36 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.9 GitCommit: e25210fe30a0a703442421b0f60afac609f950a3 runc: Version: 1.0.1 GitCommit: v1.0.1-0-g4144b63 docker-init: Version: 0.18.0 GitCommit: fec3683 二.卸载 1.卸载安装包 yum -y remove docker-ce yum list installed|grep docker 查看安装的包 #把查到的都删了，如下： yum –y remove docker.x86_64 yum –y remove docker-client.x86_64 yum –y remove docker-common.x86_64 2.卸载原来的旧数据 rm -rf /var/lib/docker docker启动失败的原因 错误信息：\n[root@xxx]# systemctl start docker Job for docker.service failed because the control process exited with error code. See \u0026#34;systemctl status docker.service\u0026#34; and \u0026#34;journalctl -xe\u0026#34; for details. 两个原因：\n1.mkfs.xfs版本太低，执行下面命令\nyum update xfsprogs 2./etc/docker/daemon.json格式不正确\n","permalink":"/posts/tech/docker%E5%AE%89%E8%A3%85/","summary":"本安装教程是基于Centos7版本的。并且系统已经安装了yum工具。 一.安装 docker有两个版本（EE）企业版， （CE）社区版。 社区版是开源免费的。所以我们安装的是社区版的。 步骤如下： 1.安装 yum 配置管理工具 yum install -y yum-utils device-mapper-persistent-data lvm2 2.设置 Docker 安装源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 注： yum-config-manage","title":"Docker安装"},{"content":"一、相关概念 1、webSocket WebSocket协议，客户端和服务端都可以主动的推送消息，可以是文本也可以是二进制数据\n2、SockJS JavaScript的一个封装工具包，用于与服务器建立连接，如果浏览器支持webSocket,那么浏览器就会使用webSocket来与服务器建立连接。否则就采用ajax轮询或者浏览器Stream来连接。\n3、STOMP STOMP即 Simple (or Streaming) Text Orientated Messaging Protocol 简单（流）文本定向消息协议，它提供了一个可互操作的连接格式，允许STOMP客户端 与任务STOMP消息代理进行交互。\n二、服务端 采用spring-mvc + spring-message\n1.配置web.xml（配置DispatcherServlet） \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;dispatcher\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath:spring-websocket.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;async-supported\u0026gt;true\u0026lt;/async-supported\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;dispatcher\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/springmvc/*\u0026lt;/url-pattern\u0026gt; \u0026lt;!-- springmvc 只拦截 配置的路径（注意在url解析时会自动去掉‘springmvc’,所以客户端请求的url需要加上这里配置的\u0026#39;springmvc\u0026#39;） --\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 2.配置spring-websocket.xml \u0026lt;context:component-scan base-package=\u0026#34;com.mustr\u0026#34;\u0026gt;\u0026lt;!-- 包扫描--\u0026gt; \u0026lt;mvc:annotation-driven/\u0026gt; 3.配置WebSocketStompConfig package com.mustr.config; import org.springframework.context.annotation.Configuration; import org.springframework.messaging.simp.config.MessageBrokerRegistry; import org.springframework.web.socket.config.annotation.AbstractWebSocketMessageBrokerConfigurer; import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker; import org.springframework.web.socket.config.annotation.StompEndpointRegistry; @Configuration @EnableWebSocketMessageBroker public class WebSocketStompConfig extends AbstractWebSocketMessageBrokerConfigurer { public void registerStompEndpoints(StompEndpointRegistry registry) { //监听端点 registry.addEndpoint(\u0026#34;/endpoint\u0026#34;) .setAllowedOrigins(\u0026#34;*\u0026#34;)//允许所有的url访问。 .withSockJS();//启用SockJS } @Override public void configureMessageBroker(MessageBrokerRegistry registry) { // 表明在topic、queue、user这二个域上可以向客户端发消息。 registry.enableSimpleBroker(\u0026#34;/topic\u0026#34;, \u0026#34;/queue\u0026#34;, \u0026#34;/user/\u0026#34;); // 客户端向服务端发起请求时，需要以/app为前缀。 registry.setApplicationDestinationPrefixes(\u0026#34;/app\u0026#34;); // 给指定用户发送一对一的消息前缀是/user。 默认就是user registry.setUserDestinationPrefix(\u0026#34;/user/\u0026#34;); //使用ActiveMQ作为broker配置 /*registry.enableStompBrokerRelay(\u0026#34;/topic\u0026#34;, \u0026#34;/queue\u0026#34;, \u0026#34;/user/\u0026#34;) .setRelayHost(\u0026#34;localhost\u0026#34;) .setRelayPort(61613)//ActiveMQ stomp端口 .setClientLogin(\u0026#34;dascom\u0026#34;) .setClientPasscode(\u0026#34;dascom\u0026#34;); registry.setApplicationDestinationPrefixes(\u0026#34;/app\u0026#34;);*/ //发送消息时，采用线程池 registry.configureBrokerChannel().taskExecutor(); } } 三、客户端 1.引用相关的js \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/sockjs.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/stomp.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 2.连接服务器 var url = \u0026#39;http://127.0.0.1:8080/trunk/springmvc/endpoint\u0026#39;; //注意springmvc不能少，服务端解析会自动去掉 var sock = new SockJS(url); var stomp = Stomp.over(sock); //stomp.debug = null;// 禁用debug日志 stomp.connect({ 请求头（可以为null） },function(frame){ stomp.subscribe(\u0026#34;/user/123/mess\u0026#34;, testUserMess); stomp.subscribe(\u0026#34;/topic/test\u0026#34;, testTopic); //stomp.subscribe(\u0026#34;/topic\u0026#34;, topic); //stomp.subscribe(\u0026#34;/queue\u0026#34;, queue); //stomp.subscribe(\u0026#34;/queue/4433/class\u0026#34;, testQueue); }); function testTopic(message) { console.log(\u0026#34;/topic/test:\u0026#34; +message.body); } function testUserMess(message) { console.log(\u0026#34;/user/123/mess:\u0026#34; +message.body); } 3.Stomp API 3.1 connect() 连接方法 client.connect(login, passcode, connectCallback); client.connect(login, passcode, connectCallback, errorCallback); client.connect(login, passcode, connectCallback, errorCallback, host); login（用户名）和passcode（密码）是strings，connectCallback和errorCallback则是functions。（有些brokers（代理）还需要传递一个host（String类型）参数。）\n如果你需要附加一个headers头部，connect方法还接受其他两种形式的参数：\nclient.connect(headers, connectCallback); client.connect(headers, connectCallback, errorCallback); //如果你使用上述这种方式，你需要自行在headers添加login,passcode（甚至host）： //如： var headers = { login: \u0026#39;mylogin\u0026#39;, passcode: \u0026#39;mypasscode\u0026#39;, // additional header \u0026#39;client-id\u0026#39;: \u0026#39;my-client-id\u0026#39; }; client.connect(headers, connectCallback); header是map形式，connectCallback和errorCallback为functions。\n3.2 disconnect()断开连接 client.disconnect(function() { //do something }; 3.3 send()发送消息 client.send(destination, {}, body);//目的地， 请求头 ， 消息体 //如： client.send(\u0026#34;/topic/test\u0026#34;, {priority: 9}, \u0026#34;Hello, STOMP\u0026#34;); //client会发送一个STOMP发送帧给/topic/test，这个帧包含一个设置了priority为9的header和内容为“Hello, STOMP”的body。 3.4订阅（Subscribe）和接收（receive）消息 使用subscribe()去订阅。这个方法有2个必需的参数：目的地(destination)，回调函数(callback)；还有一个可选的参数headers。其中destination是String类型，对应目的地，回调函数是伴随着一个参数的function类型。\nvar subscription = client.subscribe(\u0026#34;/queue/test\u0026#34;, callback); subscribe()方法返回一个object，这个object包含一个id属性，对应这个这个客户端的订阅ID。而unsubscribe()可以用来取消客户端对这个目的地destination的订阅。\n默认情况下，如果没有在headers额外添加，这个库会默认构建一个独一无二的ID。在传递headers这个参数时，可以使用你自己的ID:\nvar mysubid = \u0026#39;...\u0026#39;; var subscription = client.subscribe(destination, callback, { id: mysubid }); 这个客户端会向服务端发送一个STOMP订阅帧（SUBSCRIBE frame）并注册回调事件。每次服务端向客户端发送消息时，客户端都会轮流调用回调函数，参数为对应消息的STOMP帧对象（Frame object）。如下所示：\ncallback = function(message) { // called when the client receives a STOMP message from the server if (message.body) { console.log(\u0026#34;got message with body \u0026#34; + message.body) } else { console.log(\u0026#34;got empty message\u0026#34;); } }); subscribe()方法，接受一个可选的headers参数用来标识附加的头部。\nvar headers = {ack: \u0026#39;client\u0026#39;, \u0026#39;selector\u0026#39;: \u0026#34;location = \u0026#39;Europe\u0026#39;\u0026#34;}; client.subscribe(\u0026#34;topic/test\u0026#34;, message_callback, headers); 这个客户端指定了它会确认接收的信息，只接收符合这个selector : location = 'Europe'的消息。\n如果想让客户端订阅多个目的地，你可以在接收所有信息的时候调用相同的回调函数：\nonmessage = function(message) { // called every time the client receives a message } var sub1 = client.subscribe(\u0026#34;/topic/test\u0026#34;, onmessage); var sub2 = client.subscribe(\u0026#34;/topic/another\u0026#34;, onmessage) 如果要中止接收消息，客户端可以在subscribe()返回的object对象调用unsubscribe()来结束接收。\nvar subscription = client.subscribe(...); ... subscription.unsubscribe(); 3.5支持JSON STOMP消息的body必须为字符串。如果你需要发送/接收JSON对象，你可以使用JSON.stringify()和JSON.parse()去转换JSON对象。\nvar quote = {symbol: \u0026#39;APPL\u0026#39;, value: 195.46}; client.send(\u0026#34;/topic/stocks\u0026#34;, {}, JSON.stringify(quote)); client.subcribe(\u0026#34;/topic/stocks\u0026#34;, function(message) { var quote = JSON.parse(message.body); console.log(quote.symbol + \u0026#34; is at \u0026#34; + quote.value); }; 四、nginx配置 使用nginx做代理的需要的配置例子：\nupstream zp_server1{ #ip_hash; #server 127.0.0.1:8888; server 127.0.0.1:8080 weight=1; #server 127.0.0.1:805; server 127.0.0.1:806 weight=1; #server 127.0.0.1:807; #server 127.0.0.1:808; #server 127.0.0.1:809; } map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://zp_server1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } 注意其中map，location部分。\n","permalink":"/posts/tech/springboot%E9%9B%86%E6%88%90websocket/","summary":"一、相关概念 1、webSocket WebSocket协议，客户端和服务端都可以主动的推送消息，可以是文本也可以是二进制数据 2、SockJS JavaScript的一个封装工具包，用于与服务器建立连接，如果浏览器支持webSocket,那么浏览器就会使用webSocket来与服务器建","title":"Springboot集成websocket"},{"content":"一、制作cxj-converter镜像 这个镜像是我自己做的，该工具的官方提供了自己的镜像，但是都没有包含多个工具的镜像。所有我自己结合两个工具，制作一个合体镜像。\n2.1 Dockerfile内容 FROM jrottenberg/ffmpeg:4.2-ubuntu1804 MAINTAINER chenxj\u0026lt;harry_mu@163.com\u0026gt; RUN apt-get clean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* \\ \u0026amp;\u0026amp; apt-get update \\ \u0026amp;\u0026amp; apt-get install -y openjdk-8-jdk \\ ghostscript \\ libxinerama1 \\ libdbus-glib-1-2 \\ libcairo2 \\ libcups2 \\ libgl1-mesa-dri \\ libgl1-mesa-glx \\ libsm6 \\ fonts-opensymbol \\ hyphen-fr \\ hyphen-de \\ hyphen-en-us \\ hyphen-it \\ hyphen-ru \\ fonts-dejavu \\ fonts-dejavu-core \\ fonts-dejavu-extra \\ fonts-dustin \\ fonts-f500 \\ fonts-fanwood \\ fonts-freefont-ttf \\ fonts-liberation \\ fonts-lmodern \\ fonts-lyx \\ fonts-sil-gentium \\ fonts-texgyre \\ fonts-tlwg-purisa \\ curl \\ --no-install-recommends \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* #把Libreoffice的安装包拷贝到指定的目录下 COPY LibreOffice_6.4.7_Linux_x86-64_deb.tar.gz /tmp/lo/ #解压Libreoffice的安装包，并安装 RUN cd /tmp/lo \\ \u0026amp;\u0026amp; tar -zxvf LibreOffice_6.4.7_Linux_x86-64_deb.tar.gz --strip-components=1 \\ \u0026amp;\u0026amp; cd DEBS \\ \u0026amp;\u0026amp; dpkg -i *.deb \\ \u0026amp;\u0026amp; rm -fr /tmp/lo #把字体目录拷贝到镜像中的指定目录下，解决中文乱码问题 COPY fonts /usr/share/fonts/ RUN ln -s /opt/libreoffice6.4/program/soffice /usr/bin/soffice ENV PATH $PATH:/opt/libreoffice6.4/program 🤔 提示\ncxj-converter镜像是基于ffmpeg:4.2的镜像的。在把libreoffice融入到其中去。其中也包含了安装jdk。 其中包含的libreoffice的相关文件路径：\n链接：https://pan.baidu.com/s/18HGdAfTe1pK5Lvor5TXQRg 提取码：y0iz # 如果链接失效，加微信/QQ联系 二、使用案例 FH 的Dockerfile文件 #基础镜像 FROM 192.168.1.33:1027/cxj-converter MAINTAINER chenxj #项目jar包的位置 ENV JAR_FILE=target/dascom-fh-10.0.0.jar #默认的jvm大小 ENV JAVA_OPTS=\u0026#34;-Xms1024m -Xmx1024m\u0026#34; WORKDIR / #创建存放项目的目录 RUN mkdir -p suite/config #把项目文件拷贝到容器中 COPY $JAR_FILE /suite/app.jar #时区问题 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo \u0026#39;Asia/Shanghai\u0026#39; \u0026gt;/etc/timezone #暴露8080端口 EXPOSE 8080 WORKDIR /suite ENTRYPOINT exec java $JAVA_OPTS -jar app.jar $BOOT_OPTS 可以看到第二行，FROM了一个基础镜像。这个镜像其实就是包含了ffmpeg和Libreoffice\n🤔 工具说明\nffmpeg: 视频，音频...等处理工具 Libreoffice:处理文档转换的工具 其他的命令就看注释即可。\n🤔 注意\n1. cxj-converter的ffmpeg, 命令在任何地方都可以执行 2. liberoffice的officeHome在/opt/libreoffice6.4。 如果结合jodconverter工具使用的话，配置 officeHome: /opt/libreoffice6.4 ","permalink":"/posts/blog/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E6%9C%8D%E5%8A%A1%E9%95%9C%E5%83%8F/","summary":"一、制作cxj-converter镜像 这个镜像是我自己做的，该工具的官方提供了自己的镜像，但是都没有包含多个工具的镜像。所有我自己结合两个工具，制作一个合体镜像。 2.1 Dockerfile内容 FROM jrottenberg/ffmpeg:4.2-ubuntu1804 MAINTAINER chenxj\u0026lt;harry_mu@163.com\u0026gt; RUN apt-get clean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* \\ \u0026amp;\u0026amp; apt-get update \\ \u0026amp;\u0026amp; apt-get install -y openjdk-8-jdk \\ ghostscript \\ libxinerama1 \\ libdbus-glib-1-2 \\ libcairo2 \\ libcups2 \\ libgl1-mesa-dri \\ libgl1-mesa-glx \\ libsm6 \\ fonts-opensymbol \\ hyphen-fr \\ hyphen-de \\ hyphen-en-us","title":"自定义文件转换服务镜像"},{"content":"","permalink":"/posts/life/life/","summary":"","title":"Life"},{"content":"","permalink":"/posts/read/read/","summary":"","title":"Read"},{"content":"关于我\n英文名: mustr 职业: 程序员 运动: 跑步、户外、电子竞技 ","permalink":"/about/","summary":"关于我 英文名: mustr 职业: 程序员 运动: 跑步、户外、电子竞技","title":"🙋🏻‍♂️关于"},{"content":"\r沐码阁\r一个记录技术、阅读、生活的博客\r✉友链格式\r名称： 沐码阁 网址： https://mustr.github.io/ 图标： https://mustr.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 ✉友链申请要求\r秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n🍻Hugo博客交流群\r937830864\n","permalink":"/links/","summary":"沐码阁 一个记录技术、阅读、生活的博客 ✉友链格式 名称： 沐码阁 网址： https://mustr.github.io/ 图标： https://mustr.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 ✉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内 🍻Hugo博客交流群 937830864","title":"🤝友链"}]